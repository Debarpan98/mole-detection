{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2fd68a7-6925-4daa-9adc-740e324c047b",
   "metadata": {},
   "source": [
    "# Ensemble on probabilities (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b59842-a478-4409-96c1-1a3218781c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from collections import Counter\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK, plotting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hpsklearn import HyperoptEstimator\n",
    "from hyperopt import tpe\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d833b2af-90c2-4ed7-84e9-8a80635ce131",
   "metadata": {},
   "source": [
    "## 1. Create ensemble model dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ce788e-caad-4994-8840-b214b56481a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_merge_file(mode):\n",
    "#     df =pd.read_csv(f'gs://oro-ds-test-bucket/sdd_acne_files/mlflow_prod/f7d0540ba8eb49f2acab131e6548f037/artifacts/all_preds/vit-0-{mode}_ensemble_all_predictions.csv')\n",
    "#     df =df.merge(pd.read_csv(f'gs://oro-ds-test-bucket/sdd_acne_files/mlflow_prod/f7d0540ba8eb49f2acab131e6548f037/artifacts/all_preds/vit-1-{mode}_ensemble_all_predictions.csv'), on=['src', 'label'], how='outer')\n",
    "#     df =df.merge(pd.read_csv(f'gs://oro-ds-test-bucket/sdd_acne_files/mlflow_prod/f7d0540ba8eb49f2acab131e6548f037/artifacts/all_preds/bit-0-{mode}_ensemble_all_predictions.csv'), on=['src', 'label'], how='outer')\n",
    "#     df =df.merge(pd.read_csv(f'gs://oro-ds-test-bucket/sdd_acne_files/mlflow_prod/f7d0540ba8eb49f2acab131e6548f037/artifacts/all_preds/bit-1-{mode}_ensemble_all_predictions.csv'), on=['src', 'label'], how='outer')\n",
    "#     return df\n",
    "# df_val = create_merge_file('val')\n",
    "# df_train = create_merge_file('train')\n",
    "# df_train =df_train.dropna()\n",
    "# df_all = pd.concat([df_val,df_train])\n",
    "# test_data = create_merge_file('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56aaece5-27d6-4024-9301-030c1399770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_val = pd.read_csv('34.152.54.213')\n",
    "df_train = pd.read_csv('Merged_For_Ensemble_probs.csv')\n",
    "df_train =df_train.dropna()\n",
    "test_data = pd.read_csv('test_Merged_For_Ensemble_probs.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675ac765-7596-4ec5-84ac-faaacb8057ba",
   "metadata": {},
   "source": [
    "Here we want to divide the training set in training and validation set.\n",
    "We use the file named 'vit_test.csv' to create the validation set.\n",
    "In fact, all the images contain in this file were use to validate the various models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9950245b-4f19-49cb-8674-0f80f822421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 988 images in the validation set.\n",
      "There are 5593 images in the training set.\n"
     ]
    }
   ],
   "source": [
    "df_val = pd.read_csv('bit_test.csv')\n",
    "df_val['src'] = df_val['filename'].apply(lambda x: x.split('/')[-1])\n",
    "masks =df_train['src'].isin(df_val['src'].unique())\n",
    "df_val= df_train[masks]\n",
    "df_training = df_train[~masks]\n",
    "print(f'There are {df_val.shape[0]} images in the validation set.')\n",
    "print(f'There are {df_training.shape[0]} images in the training set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ef95a1-cddf-40cc-86a5-4b7736c106a4",
   "metadata": {},
   "source": [
    "The validation set is used to finetuned the hyperparameters of the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "057ece1b-e0c5-47ac-95cd-39c75c546170",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = set(df_train.columns)\n",
    "columns.remove('true_label')\n",
    "columns.remove('src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a7451-9ad3-4c0c-83de-4f492c076bc2",
   "metadata": {},
   "source": [
    "Once we find the best combination of hyperparameters, we use all the training + validation images to train the emsemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "977c79b6-0a8b-4202-902e-3bd3ef48dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final training set \n",
    "train_data= df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0839b9-586e-435b-a795-90420a11a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = train_data[columns], train_data['true_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fdf058-7b2d-47a1-948b-db5ed4c70f72",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter search -> Hyperopt search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b70b6def-2f0f-4e67-88ab-11debf3b09c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_classification_report(df_preds: pd.DataFrame, k: int, classes: list):\n",
    "    \"\"\"Generate top-3 classification report\n",
    "\n",
    "    Args:\n",
    "        df_preds (pd.DataFrame): predictions\n",
    "        classes (list): list of classes\n",
    "\n",
    "    Returns:\n",
    "        dict: top-3 classification report\n",
    "    \"\"\"        \n",
    "    exp_name= 'top'+str(k)+'_prediction'\n",
    "    print(exp_name)\n",
    "    prob_columns = ['prob_' + disease for disease in classes]\n",
    "    preds_list = []\n",
    "    for i in range(k):\n",
    "        str_name = 'Pred'+ str(i+1) \n",
    "        str_name_probs = 'Prob' + str(i+1)\n",
    "        preds_list.append(str_name)\n",
    "        df_preds[str_name] =df_preds[prob_columns].apply(lambda x: x.sort_values(ascending=False).index[i].replace('prob_', ''), axis=1)\n",
    "        df_preds[str_name_probs] = df_preds[prob_columns].apply(lambda x: x.sort_values(ascending=False).values[1], axis=1)\n",
    "    df_preds['labels'] = df_preds['label']\n",
    "    df_preds[exp_name] = df_preds.apply(lambda row: bool(set([row['labels']]).intersection(set(row[preds_list].values))), axis=1).reset_index(drop=True)\n",
    "    #print(f\"{exp_name} Accuracy: {df_preds[exp_name].value_counts()[True]/df_preds.shape[0]:0.3f}%.\")\n",
    "    y_pred = df_preds.apply(lambda x : x['labels'] if x[exp_name] else x['Pred1'] , axis=1).to_list()\n",
    "    y_score = df_preds.apply(lambda x : x['labels'], axis=1).to_list()\n",
    "    report = classification_report( y_score,y_pred, digits=4, output_dict=True)\n",
    "    #print(classification_report( y_score,y_pred, digits=4, output_dict=False))\n",
    "    return pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d504526-44b8-473b-9b71-02425474cee3",
   "metadata": {},
   "source": [
    "We are trying to find the best combination of these hyperparameters: [learning_rate, max_depth, min_child_weight, gamma, subsample, colsample_bytree\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d59ac93-353c-4054-a720-b0c082a27202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize():\n",
    "    space = {\n",
    "            'learning_rate': hp.quniform('learning_rate', 0.01, 0.3, 0.001),\n",
    "            # Control complexity (control overfitting)\n",
    "            # Maximum depth of a tree: default 6 -> range: [0:∞]\n",
    "            'max_depth':  hp.choice('max_depth', np.arange(5, 10, dtype=int)),\n",
    "            # Minimum sum of instance weight (hessian) needed in a child: default 1\n",
    "            'min_child_weight': hp.quniform('min_child_weight', 1, 3, 1),\n",
    "            # Minimum loss reduction required: default 0 -> range: [0,∞]\n",
    "            'gamma': hp.quniform('gamma', 0, 5, 0.5),\n",
    "\n",
    "            # Add randomness to make training robust to noise (control overfitting)\n",
    "            # Subsample ratio of the training instance: default 1\n",
    "            'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "            # Subsample ratio of columns when constructing each tree: default 1\n",
    "            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "            \n",
    "            # For reproducibility\n",
    "            'seed': 42,\n",
    "            # Faster computation\n",
    "            'tree_method':'gpu_hist'\n",
    "            }\n",
    "        \n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=500)\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fedd730-ee85-4602-be9a-823350506a97",
   "metadata": {},
   "source": [
    "We use the validation set to evaluate the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dc29aa2-a65f-4caf-a79c-4b1f3881a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_training[columns].reset_index(drop=True),df_training['true_label'].reset_index(drop=True)\n",
    "X_test, y_test = df_val[columns].reset_index(drop=True), df_val['true_label'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b777966-2184-45d2-902d-526561e8b7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    #print(params)\n",
    "    xg_reg = xgb.XGBClassifier(**params)\n",
    "    xg_reg.fit(X_train,y_train)\n",
    "    \n",
    "    preds_probs = xg_reg.predict_proba(X_test)\n",
    "    #preds_probs = xg_reg.predict_proba(test_data[columns])  \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(xg_reg.classes_)\n",
    "    \n",
    "    df_final = pd.DataFrame()\n",
    "    df_final['Pred1'] =le.inverse_transform(np.flip(np.argsort(preds_probs),axis=1)[:, 0])\n",
    "    df_final['Pred2'] =le.inverse_transform(np.flip(np.argsort(preds_probs),axis=1)[:, 1])\n",
    "    df_final['Pred3'] =le.inverse_transform(np.flip(np.argsort(preds_probs),axis=1)[:, 2])\n",
    "    \n",
    "    df_final['label'] = y_test #test_data['label']\n",
    "    preds_list =['Pred1', 'Pred2', 'Pred3']\n",
    "    df_final['is_top_3'] = df_final.apply(lambda row: bool(set([row['label']]).intersection(set(row[preds_list].values))), axis=1)\n",
    "    df_final['preds'] = df_final.apply(lambda x : x['label'] if x['is_top_3'] else x['Pred1'] , axis=1)\n",
    "\n",
    "    score = accuracy_score(df_final['label'], df_final['preds'])\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f40e68e-8725-4842-b72c-c99aa8529fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ...\n",
      "The best hyperparameters are: {'colsample_bytree': 1.0, 'gamma': 4.5, 'learning_rate': 0.28, 'max_depth': 1, 'min_child_weight': 3.0, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = optimize()\n",
    "print(f'The best hyperparameters are: {best_hyperparams}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee67404-e498-438c-b88d-de8748cbb35a",
   "metadata": {},
   "source": [
    "Let's visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "045c6dea-dc84-4a6c-8086-4793f6461bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trials as a pandas dataframe\n",
    "summary_table = pd.DataFrame()\n",
    "\n",
    "for i in range(len(trials.trials)-1):\n",
    "    row = pd.concat([pd.DataFrame({'loss':[trials.trials[i]['result']['loss']]}), \\\n",
    "                     pd.DataFrame(trials.trials[i]['misc']['vals'])], axis=1)\n",
    "    summary_table = summary_table.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c316e947-20f0-4307-b971-54b658248dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.782389</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.280</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.783401</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.299</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.785425</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.785425</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.785425</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.785425</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.786437</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.274</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.786437</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.273</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.786437</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.786437</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.786437</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.786437</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.786437</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.299</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.786437</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.786437</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787449</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787449</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787449</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787449</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787449</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.300</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.287</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.790486</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.790486</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.288</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.790486</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.299</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.790486</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.844130</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.152</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.845142</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.182</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.845142</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.845142</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.128</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.143</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.181</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.178</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.178</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.081</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.146</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.847166</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.162</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.847166</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.181</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.847166</td>\n",
       "      <td>0.60</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.848178</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.054</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.848178</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.848178</td>\n",
       "      <td>0.60</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.024</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.848178</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.074</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849190</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.132</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849190</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.138</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849190</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.116</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.850202</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.094</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.851215</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.107</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.852227</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.133</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.852227</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.097</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.852227</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.156</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.852227</td>\n",
       "      <td>0.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.853239</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.049</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.854251</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.854251</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.124</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.857287</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.080</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  colsample_bytree  gamma  learning_rate  max_depth  \\\n",
       "0   0.782389              1.00    4.5          0.280          1   \n",
       "0   0.783401              0.95    5.0          0.299          4   \n",
       "0   0.785425              0.95    3.5          0.294          0   \n",
       "0   0.785425              0.95    4.0          0.294          0   \n",
       "0   0.785425              1.00    3.0          0.282          0   \n",
       "0   0.785425              1.00    4.0          0.281          0   \n",
       "0   0.786437              1.00    5.0          0.274          1   \n",
       "0   0.786437              1.00    4.5          0.273          1   \n",
       "0   0.786437              1.00    3.0          0.281          0   \n",
       "0   0.786437              0.90    4.0          0.300          0   \n",
       "0   0.786437              0.95    4.0          0.292          0   \n",
       "0   0.786437              0.95    3.5          0.282          0   \n",
       "0   0.786437              0.95    4.5          0.299          4   \n",
       "0   0.786437              0.90    4.0          0.283          0   \n",
       "0   0.786437              1.00    4.0          0.280          0   \n",
       "0   0.787449              0.90    3.5          0.300          0   \n",
       "0   0.787449              1.00    3.0          0.261          0   \n",
       "0   0.787449              1.00    4.0          0.277          0   \n",
       "0   0.787449              0.90    4.0          0.296          0   \n",
       "0   0.787449              1.00    4.0          0.277          0   \n",
       "0   0.788462              0.90    3.0          0.300          0   \n",
       "0   0.788462              0.90    4.0          0.293          0   \n",
       "0   0.789474              0.90    4.0          0.300          4   \n",
       "0   0.789474              0.95    3.5          0.287          1   \n",
       "0   0.789474              0.95    3.5          0.286          0   \n",
       "0   0.789474              1.00    4.0          0.258          0   \n",
       "0   0.790486              0.95    4.0          0.280          0   \n",
       "0   0.790486              0.90    3.5          0.288          1   \n",
       "0   0.790486              0.70    4.5          0.299          3   \n",
       "0   0.790486              0.95    4.0          0.276          0   \n",
       "..       ...               ...    ...            ...        ...   \n",
       "0   0.844130              0.80    2.0          0.152          3   \n",
       "0   0.845142              0.50    1.5          0.182          3   \n",
       "0   0.845142              0.75    0.0          0.139          1   \n",
       "0   0.845142              0.70    4.0          0.128          4   \n",
       "0   0.846154              0.70    4.5          0.143          3   \n",
       "0   0.846154              0.80    2.5          0.181          2   \n",
       "0   0.846154              0.80    1.5          0.178          4   \n",
       "0   0.846154              0.65    3.0          0.178          2   \n",
       "0   0.846154              0.80    4.5          0.081          4   \n",
       "0   0.846154              0.80    3.5          0.146          3   \n",
       "0   0.847166              0.50    4.5          0.162          3   \n",
       "0   0.847166              0.55    2.5          0.181          3   \n",
       "0   0.847166              0.60    5.0          0.028          2   \n",
       "0   0.848178              0.55    2.5          0.054          4   \n",
       "0   0.848178              0.65    3.0          0.085          1   \n",
       "0   0.848178              0.60    5.0          0.024          3   \n",
       "0   0.848178              0.65    4.5          0.074          2   \n",
       "0   0.849190              0.65    4.0          0.132          4   \n",
       "0   0.849190              0.85    3.5          0.138          3   \n",
       "0   0.849190              0.60    2.5          0.116          3   \n",
       "0   0.850202              0.75    3.0          0.094          3   \n",
       "0   0.851215              0.60    4.5          0.107          3   \n",
       "0   0.852227              0.65    2.0          0.133          3   \n",
       "0   0.852227              0.65    3.0          0.097          4   \n",
       "0   0.852227              0.55    4.0          0.156          3   \n",
       "0   0.852227              0.65    4.0          0.135          2   \n",
       "0   0.853239              0.55    0.5          0.049          4   \n",
       "0   0.854251              0.55    4.0          0.104          3   \n",
       "0   0.854251              0.50    2.0          0.124          2   \n",
       "0   0.857287              0.55    2.5          0.080          2   \n",
       "\n",
       "    min_child_weight  subsample  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.55  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.55  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.50  \n",
       "0                3.0       0.55  \n",
       "0                3.0       0.50  \n",
       "..               ...        ...  \n",
       "0                3.0       0.80  \n",
       "0                3.0       0.50  \n",
       "0                2.0       0.50  \n",
       "0                3.0       0.60  \n",
       "0                2.0       0.50  \n",
       "0                1.0       0.75  \n",
       "0                2.0       0.75  \n",
       "0                3.0       0.70  \n",
       "0                3.0       0.90  \n",
       "0                1.0       0.60  \n",
       "0                3.0       0.60  \n",
       "0                2.0       0.70  \n",
       "0                3.0       0.60  \n",
       "0                2.0       0.90  \n",
       "0                3.0       0.55  \n",
       "0                3.0       0.60  \n",
       "0                3.0       0.70  \n",
       "0                3.0       0.65  \n",
       "0                3.0       0.70  \n",
       "0                2.0       0.50  \n",
       "0                3.0       0.70  \n",
       "0                1.0       0.70  \n",
       "0                3.0       0.65  \n",
       "0                2.0       0.50  \n",
       "0                3.0       0.75  \n",
       "0                3.0       0.80  \n",
       "0                3.0       0.75  \n",
       "0                3.0       0.70  \n",
       "0                1.0       0.80  \n",
       "0                1.0       0.60  \n",
       "\n",
       "[499 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table.sort_values(['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e950a90-ae82-4047-b203-81b413fa5b41",
   "metadata": {},
   "source": [
    "# 3. Final XGboost model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d709ed9-ec93-4e0c-bfb8-d066f78650a8",
   "metadata": {},
   "source": [
    "We use the best combination of hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1bb430a-886a-4e77-8616-b05feea47366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(5, 10, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a63a8b0b-1fa7-4b2e-8123-d403878e9540",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBClassifier(colsample_bytree=0.55, gamma=2.5, learning_rate=0.08, max_depth=7, min_child_weight=2, subsample=1,  seed=42, tree_method='gpu_hist')\n",
    "#xg_reg = xgb.XGBClassifier(colsample_bytree=0.60, gamma=4.5, learning_rate=0.066, max_depth=5, min_child_weight=3.0, subsample=0.50,  seed=42, tree_method='gpu_hist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21824ebf-cbef-47bf-935d-5ef38c2d51f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "                       acne_comedos     0.8261    0.6552    0.7308        29\n",
      "                        acne_cystic     0.9487    0.8409    0.8916        44\n",
      "                    acne_excoriated     0.9091    0.5263    0.6667        19\n",
      "                         acne_mixed     0.8934    0.9778    0.9337       180\n",
      "                         acne_scars     0.9444    0.8500    0.8947        20\n",
      "                  actinic_keratosis     0.9375    0.8824    0.9091        17\n",
      "                alopecia_androgenic     0.9143    0.9412    0.9275        34\n",
      "                    alopecia_areata     0.8333    0.7692    0.8000        13\n",
      "                  atopic_dermatitis     0.8828    0.8692    0.8760       130\n",
      "               cheilitis_eczematous     0.7826    0.8182    0.8000        22\n",
      "                chronic_hand_eczema     0.9636    0.9636    0.9636        55\n",
      "                        dyshidrosis     0.7885    0.9762    0.8723        42\n",
      "                       folliculitis     0.9125    0.9125    0.9125        80\n",
      "                      genital_warts     0.9333    0.8750    0.9032        16\n",
      "                 granuloma_annulare     0.6667    0.3333    0.4444         6\n",
      "                     herpes_simplex     1.0000    1.0000    1.0000         6\n",
      "                         intertrigo     0.8286    0.8286    0.8286        35\n",
      "                  keratosis_pilaris     0.9259    0.9615    0.9434        26\n",
      "           lichen_simplex_chronicus     1.0000    0.2500    0.4000         4\n",
      "                       melanonychia     0.7500    0.7500    0.7500         4\n",
      "                            melasma     0.9444    0.9444    0.9444        36\n",
      "                          molluscum     0.8929    1.0000    0.9434        25\n",
      "                              nevus     0.8358    0.9180    0.8750        61\n",
      "                    nummular_eczema     0.8636    0.7917    0.8261        24\n",
      "               peri_oral_dermatitis     0.9314    0.9500    0.9406       100\n",
      "                   pityriasis_rosae     0.8889    1.0000    0.9412         8\n",
      "                        plane_warts     0.9091    0.9091    0.9091        11\n",
      "                  prurigo_nodularis     0.8421    0.7619    0.8000        21\n",
      "                  psoriasis_guttate     0.8000    0.6667    0.7273         6\n",
      "    psoriasis_pustular_palmoplantar     1.0000    0.5714    0.7273         7\n",
      "                   psoriasis_vulgar     0.9103    0.9103    0.9103        78\n",
      "rosacea_erythemato_telangiectasique     0.9126    0.9592    0.9353        98\n",
      "               rosacea_inflammatory     0.9383    0.8941    0.9157        85\n",
      "              seborrheic_dermatitis     0.8462    0.8730    0.8594        63\n",
      "               seborrheic_keratosis     0.8750    0.9545    0.9130        44\n",
      "                           shingles     1.0000    0.4000    0.5714         5\n",
      "                     tinea_corporis     0.8000    0.6000    0.6857        20\n",
      "                   tinea_versicolor     0.9867    0.9737    0.9801        76\n",
      "                          urticaria     0.8889    0.9231    0.9057        26\n",
      "                           vitiligo     0.9130    0.9130    0.9130        23\n",
      "                       vulgar_warts     0.9000    0.8710    0.8852        31\n",
      "\n",
      "                           accuracy                         0.8975      1630\n",
      "                          macro avg     0.8907    0.8236    0.8429      1630\n",
      "                       weighted avg     0.8984    0.8975    0.8947      1630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_reg.fit(X_res, y_res)\n",
    "preds_probs = xg_reg.predict_proba(test_data[columns])\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(xg_reg.classes_)\n",
    "df_final = pd.DataFrame()\n",
    "df_final['Pred1'] =le.inverse_transform(np.flip(np.argsort(preds_probs),axis=1)[:, 0])\n",
    "df_final['Pred2'] =le.inverse_transform(np.flip(np.argsort(preds_probs),axis=1)[:, 1])\n",
    "df_final['Pred3'] =le.inverse_transform(np.flip(np.argsort(preds_probs),axis=1)[:, 2])\n",
    "df_final['label'] = test_data['label']\n",
    "preds_list =['Pred1', 'Pred2', 'Pred3']\n",
    "df_final['is_top_3'] = df_final.apply(lambda row: bool(set([row['label']]).intersection(set(row[preds_list].values))), axis=1)\n",
    "df_final['preds'] = df_final.apply(lambda x : x['label'] if x['is_top_3'] else x['Pred1'] , axis=1)\n",
    "print(classification_report( df_final['label'], df_final['preds'], digits=4, output_dict=False))\n",
    "#pd.DataFrame(classification_report( df_final['label'], df_final['preds'], digits=4, output_dict=True)).transpose().to_csv('resport.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0090fe-a3f6-46e7-9b74-b4934907d72e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b3d83-0fd8-4c3a-9ff2-5f33c57cade6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_acne",
   "language": "python",
   "name": "env_acne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
